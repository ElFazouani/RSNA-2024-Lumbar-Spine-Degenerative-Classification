{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h71KTJXbS_Tz",
    "outputId": "66a49ae2-b085-4d17-adea-3eec1f48b6ae"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import random\n",
    "\n",
    "import os\n",
    "\n",
    "import glob\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import albumentations as A\n",
    "\n",
    "import pydicom\n",
    "\n",
    "import timm\n",
    "\n",
    "from transformers.optimization import AdamW, get_cosine_schedule_with_warmup\n",
    "from transformers import RobertaPreLayerNormConfig, RobertaPreLayerNormModel\n",
    "\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "from segmentation_models_pytorch.decoders.unet.model import (\n",
    "    UnetDecoder,\n",
    "    SegmentationHead,\n",
    ")\n",
    "DATA_DIR = 'input'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t5O3mtxnTC6E"
   },
   "source": [
    "## config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QyjkKpVuTDyi"
   },
   "outputs": [],
   "source": [
    "class CustomConfig:\n",
    "    seed = 42\n",
    "    device = 'cuda'\n",
    "    root = DATA_DIR\n",
    "\n",
    "    train = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "    label_columns = train.columns[1:]\n",
    "\n",
    "    ignore_index = -100\n",
    "    label2index = {'Normal/Mild' : 0, 'Moderate' : 1, 'Severe' : 2, 'Nan' : ignore_index,}\n",
    "    label2onehot = {'Normal/Mild' : [1, 0, 0], 'Moderate' : [0, 1, 0], 'Severe' : [0, 0, 1], 'Nan' : [ignore_index] * 3,}\n",
    "    label2weight = {'Normal/Mild' : 1, 'Moderate' : 2, 'Severe' : 4, 'Nan' : 0,}\n",
    "\n",
    "    scan_orientations = ['Sagittal T2/STIR', 'Sagittal T1', 'Axial T2']\n",
    "\n",
    "    n_class = 3\n",
    "    n_fold = 5\n",
    "\n",
    "    batch_size = 4\n",
    "    n_worker = 16\n",
    "\n",
    "    lr = 1e-4\n",
    "    wd = 1e-2\n",
    "    n_epoch = 20\n",
    "    warmup_ratio = 0.1\n",
    "    test_freq = 1\n",
    "\n",
    "    mix_method = 'cutmix'\n",
    "    mix_prob = 0.5\n",
    "    mix_alpha = 1.0\n",
    "\n",
    "    coordinate_columns = {\n",
    "        'Sagittal T2/STIR' : [\n",
    "            ['Spinal Canal Stenosis', 'L1/L2'],\n",
    "            ['Spinal Canal Stenosis', 'L2/L3'],\n",
    "            ['Spinal Canal Stenosis', 'L3/L4'],\n",
    "            ['Spinal Canal Stenosis', 'L4/L5'],\n",
    "            ['Spinal Canal Stenosis', 'L5/S1'],\n",
    "        ],\n",
    "        'Sagittal T1' : [\n",
    "            ['Left Neural Foraminal Narrowing', 'L1/L2'],\n",
    "            ['Left Neural Foraminal Narrowing', 'L2/L3'],\n",
    "            ['Left Neural Foraminal Narrowing', 'L3/L4'],\n",
    "            ['Left Neural Foraminal Narrowing', 'L4/L5'],\n",
    "            ['Left Neural Foraminal Narrowing', 'L5/S1'],\n",
    "\n",
    "            ['Right Neural Foraminal Narrowing', 'L1/L2'],\n",
    "            ['Right Neural Foraminal Narrowing', 'L2/L3'],\n",
    "            ['Right Neural Foraminal Narrowing', 'L3/L4'],\n",
    "            ['Right Neural Foraminal Narrowing', 'L4/L5'],\n",
    "            ['Right Neural Foraminal Narrowing', 'L5/S1'],\n",
    "        ],\n",
    "        'Axial T2' : [\n",
    "            ['Left Subarticular Stenosis', 'L1/L2'],\n",
    "            ['Left Subarticular Stenosis', 'L2/L3'],\n",
    "            ['Left Subarticular Stenosis', 'L3/L4'],\n",
    "            ['Left Subarticular Stenosis', 'L4/L5'],\n",
    "            ['Left Subarticular Stenosis', 'L5/S1'],\n",
    "\n",
    "            ['Right Subarticular Stenosis', 'L1/L2'],\n",
    "            ['Right Subarticular Stenosis', 'L2/L3'],\n",
    "            ['Right Subarticular Stenosis', 'L3/L4'],\n",
    "            ['Right Subarticular Stenosis', 'L4/L5'],\n",
    "            ['Right Subarticular Stenosis', 'L5/S1'],\n",
    "        ],\n",
    "    }\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    args = CustomConfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JpOm4ClDTQuy"
   },
   "source": [
    "## seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "koQGTWpzTR1R"
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    seed_everything(args.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iOaNHqoITdt4"
   },
   "source": [
    "## preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SFILGbcgTfSs"
   },
   "outputs": [],
   "source": [
    "def preprocess(args):\n",
    "    train = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "\n",
    "    folds = []\n",
    "\n",
    "    kf = KFold(n_splits = args.n_fold, shuffle = True, random_state = args.seed)\n",
    "    for train_indices, test_indices in kf.split(train):\n",
    "\n",
    "        train_df = train.loc[train_indices].reset_index(drop = True)\n",
    "        test_df = train.loc[test_indices].reset_index(drop = True)\n",
    "\n",
    "        folds.append([train_df, test_df])\n",
    "\n",
    "    return train, folds\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train, folds = preprocess(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "numIyizDD0FY"
   },
   "source": [
    "## utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u-uPyp7RIJ4h"
   },
   "outputs": [],
   "source": [
    "def volume2point(volumes):\n",
    "    volumes = volumes.cpu()\n",
    "\n",
    "    batch_size, n_class, _, h, w = volumes.shape\n",
    "\n",
    "    points = []\n",
    "    for i in range(batch_size):\n",
    "        volume = volumes[i]\n",
    "\n",
    "        point = []\n",
    "        for j in range(n_class):\n",
    "            flat_volume = volume[j].reshape(-1)\n",
    "            max_idx = torch.argmax(flat_volume)\n",
    "\n",
    "            z = max_idx // (h * w)\n",
    "            y = (max_idx % (h * w)) // w\n",
    "            x = (max_idx % (h * w)) % w\n",
    "            point.append(torch.stack([z, y, x]))\n",
    "\n",
    "        point = torch.stack(point, dim = 0)\n",
    "        points.append(point)\n",
    "\n",
    "    points = torch.stack(points, dim = 0)\n",
    "    return points.numpy()\n",
    "\n",
    "\n",
    "\n",
    "def volume2point2(volumes):\n",
    "    volumes = volumes.cpu()\n",
    "\n",
    "    batch_size, n_class, _, h, w = volumes.shape\n",
    "\n",
    "    points = []\n",
    "    for i in range(batch_size):\n",
    "        volume = volumes[i]\n",
    "\n",
    "        point = []\n",
    "        for j in range(n_class):\n",
    "            flat_volume = volume[j].reshape(-1)\n",
    "            max_idx = torch.argmax(flat_volume)\n",
    "\n",
    "            max_idxs = []\n",
    "            for k in [-9, -7, -5, -3, -1, 1, 3, 5, 7]:\n",
    "                idx_start = max_idx + k*(h*w)//2\n",
    "                idx_start = max(0, idx_start)\n",
    "                idx_start = min(idx_start, flat_volume.shape[0]-h*w)\n",
    "                max_idxs.append(idx_start + torch.argmax(flat_volume[idx_start:idx_start + h*w]))\n",
    "\n",
    "            z = max_idx // (h * w)\n",
    "            y = [(idx % (h * w)) // w for idx in max_idxs]\n",
    "            x = [(idx % (h * w)) % w for idx in max_idxs]\n",
    "            point.append(torch.stack([z] +  y + x))\n",
    "\n",
    "        point = torch.stack(point, dim = 0)\n",
    "        points.append(point)\n",
    "\n",
    "    points = torch.stack(points, dim = 0)\n",
    "    return points.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dSn87JHUQpcn"
   },
   "source": [
    "## dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lwYHXmcNU2jb"
   },
   "outputs": [],
   "source": [
    "def convert_to_8bit(x):\n",
    "    lower, upper = np.percentile(x, (1, 99))\n",
    "    x = np.clip(x, lower, upper)\n",
    "    x = x - np.min(x)\n",
    "    x = x / np.max(x)\n",
    "    return (x * 255).astype(\"uint8\")\n",
    "\n",
    "def get_imgs(dcms):\n",
    "    imgs = []\n",
    "    for dcm in dcms:\n",
    "        img = convert_to_8bit(dcm.pixel_array)\n",
    "        imgs.append(img)\n",
    "\n",
    "    try:\n",
    "        return np.stack(imgs, axis = 0)\n",
    "    except:\n",
    "        h, w = imgs[0].shape\n",
    "        imgs = [A.Resize(h, w)(image = x)['image'] for x in imgs]\n",
    "        return np.stack(imgs, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "hJCshgEG-kRR",
    "outputId": "bab31cd1-44bb-4274-c522-cf9d20a18096"
   },
   "outputs": [],
   "source": [
    "class DetectDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, args, df, orientation):\n",
    "        self.args = args\n",
    "        self.df = df\n",
    "        self.orientation = orientation\n",
    "\n",
    "        self.volume_size = {\n",
    "            'Sagittal T2/STIR' : [29, 256, 256],\n",
    "            'Sagittal T1' : [38, 256, 256],\n",
    "            'Axial T2' : [192, 256, 256]\n",
    "        }[orientation]\n",
    "\n",
    "        self.train_series_descriptions = pd.read_csv(f'{DATA_DIR}/train_series_descriptions.csv')\n",
    "        self.train_label_coordinates = pd.read_csv(f'{DATA_DIR}/coords_rsna_improved.csv')\n",
    "\n",
    "    \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def get_subvolume(self, study_id, series_id):\n",
    "        dicoms = sorted(glob.glob(self.args.root + f'/train_images/{study_id}/{series_id}/*.dcm'), key = lambda x: int(x.split('/')[-1].split('.')[0]))     \n",
    "        dicoms = [pydicom.dcmread(x) for x in dicoms]\n",
    "        \n",
    "        if 'Sagittal' in self.orientation:\n",
    "            pos = np.asarray([dicom.ImagePositionPatient for dicom in dicoms])[:, 0]\n",
    "        else:\n",
    "            pos = np.asarray([dicom.ImagePositionPatient for dicom in dicoms])[:, -1]\n",
    "            orien = np.asarray([dicom.ImageOrientationPatient for dicom in dicoms])\n",
    "\n",
    "\n",
    "        inputs = get_imgs(dicoms)\n",
    "        inputs = A.Resize(self.volume_size[1], self.volume_size[2])(image = inputs.transpose(1, 2, 0))['image'].transpose(2, 0, 1)\n",
    "        inputs = torch.tensor(inputs, dtype = torch.float)\n",
    "        inputs = inputs / 255.0\n",
    "\n",
    "        return inputs, pos\n",
    "\n",
    "    def get_inputs(self, row):\n",
    "        row_series_descriptions = self.train_series_descriptions[self.train_series_descriptions['study_id'] == row['study_id']]\n",
    "        row_series_descriptions = row_series_descriptions[row_series_descriptions['series_description'] == self.orientation].reset_index(drop = True)\n",
    "        \n",
    "        \n",
    "        if len(row_series_descriptions) > 0:\n",
    "            inputs, pos = [], []\n",
    "            for i in range(len(row_series_descriptions)):\n",
    "                study_id, series_id, _ = row_series_descriptions.loc[i]\n",
    "                \n",
    "                _inputs, _pos = self.get_subvolume(study_id, series_id)\n",
    "                inputs.append(_inputs)\n",
    "                pos.append(_pos)\n",
    "\n",
    "            inputs = torch.cat(inputs, dim = 0)\n",
    "            pos = np.concatenate(pos, axis = 0)\n",
    "        else:\n",
    "            inputs = torch.zeros(self.volume_size, dtype = torch.float32)\n",
    "            pos = np.zeros([self.volume_size[0]], dtype = np.float32)\n",
    "\n",
    "        return inputs, pos\n",
    "\n",
    "    def get_targets(self, row, inputs):\n",
    "        row_series_descriptions = self.train_series_descriptions[self.train_series_descriptions['study_id'] == row['study_id']]\n",
    "        row_series_descriptions = row_series_descriptions[row_series_descriptions['series_description'] == self.orientation].reset_index(drop = True)\n",
    "        targets = np.zeros([len(self.args.coordinate_columns[self.orientation])] + [inputs.shape[0]] + self.volume_size[1:], dtype = np.float32)\n",
    "\n",
    "        if len(row_series_descriptions) > 0:\n",
    "            dicoms = []\n",
    "            series_ids = []\n",
    "            for i in range(len(row_series_descriptions)):\n",
    "                study_id, series_id, _ = row_series_descriptions.loc[i]\n",
    "\n",
    "                d = sorted(glob.glob(f'{DATA_DIR}/train_images/{study_id}/{series_id}/*.dcm'), key = lambda x: int(x.split('/')[-1].split('.')[0]))\n",
    "                series_ids += [series_id]*len(d)\n",
    "                dicoms += d\n",
    "            instance_numbers = [int(x.split('/')[-1].split('.')[0]) for x in dicoms]\n",
    "            instance_serie2index = {(instance_numbers[i], series_ids[i]):i for i in range(len(instance_numbers))}\n",
    "\n",
    "            for series_id in set(series_ids):\n",
    "                label_coordinate = self.train_label_coordinates[(self.train_label_coordinates['study_id'] == study_id) & (self.train_label_coordinates['series_id'] == series_id)].reset_index(drop = True)\n",
    "                for i in range(len(self.args.coordinate_columns[self.orientation])):\n",
    "\n",
    "                    condition, level = self.args.coordinate_columns[self.orientation][i][0], self.args.coordinate_columns[self.orientation][i][1]\n",
    "                    try:\n",
    "                        if self.orientation == 'Sagittal T2/STIR':\n",
    "                            _, _, x, y, _, _, instance_number, _, _ = label_coordinate[(label_coordinate['condition'] == condition) & (label_coordinate['level'] == level) & (label_coordinate['side'] == 'R')].reset_index(drop = True).loc[0]\n",
    "                        else:\n",
    "                            _, _, x, y, _, _, instance_number, _, _ = label_coordinate[(label_coordinate['condition'] == condition) & (label_coordinate['level'] == level)].reset_index(drop = True).loc[0]\n",
    "                    except:\n",
    "                        continue;\n",
    "                    h, w = pydicom.dcmread(f'{DATA_DIR}/train_images/{study_id}/{series_id}/{instance_number}.dcm').pixel_array.shape\n",
    "                    z = instance_serie2index[(instance_number, series_id)]\n",
    "\n",
    "                    z_i = z\n",
    "                    y_i = round(y * (self.volume_size[1]))\n",
    "                    x_i = round(x * (self.volume_size[2]))\n",
    "\n",
    "                    targets[i, z_i, y_i, x_i] = 1\n",
    "\n",
    "                    targets[i, z_i] = gaussian_filter(targets[i, z_i], sigma = (4, 4))\n",
    "                    targets[i, z_i] = targets[i, z_i] / targets[i, z_i].max()\n",
    "\n",
    "                    targets[i, max(0, z_i - 2)] = targets[i, z_i] / 2**2\n",
    "                    targets[i, max(0, z_i - 1)] = targets[i, z_i] / 2**1\n",
    "\n",
    "                    targets[i, min(targets.shape[1] - 1, z_i + 2)] = targets[i, z_i] / 2**2\n",
    "                    targets[i, min(targets.shape[1] - 1, z_i + 1)] = targets[i, z_i] / 2**1\n",
    "\n",
    "        targets = torch.tensor(targets, dtype = torch.float)\n",
    "        return targets\n",
    "\n",
    "    def get_masks(self, inputs, targets):\n",
    "        temporal_masks = (inputs.sum(dim = [1, 2]) != 0).float()\n",
    "        spatial_masks = (targets.sum(dim = [1, 2, 3]) != 0).float()\n",
    "\n",
    "        masks = temporal_masks[None, :] * spatial_masks[:, None]\n",
    "        return masks\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.loc[index]\n",
    "        inputs, pos = self.get_inputs(row)\n",
    "        targets = self.get_targets(row, inputs)\n",
    "\n",
    "        pos = np.argsort(pos)\n",
    "\n",
    "        inputs = inputs[pos]\n",
    "        targets = targets[:, pos]\n",
    "\n",
    "        if inputs.shape[0] > self.volume_size[0]:\n",
    "            inputs = F.interpolate(inputs.unsqueeze(0).unsqueeze(0), size = self.volume_size, mode = 'trilinear').squeeze(0).squeeze(0)\n",
    "            targets = F.interpolate(targets.unsqueeze(0), size = self.volume_size, mode = 'trilinear').squeeze(0)\n",
    "\n",
    "        \n",
    "        inputs = torch.cat([inputs, torch.zeros([self.volume_size[0] - inputs.shape[0]] + list(inputs.shape[1:]), dtype = torch.float)], dim = 0)\n",
    "        targets = torch.cat([targets, torch.zeros([len(self.args.coordinate_columns[self.orientation])] + [self.volume_size[0] - targets.shape[1]] + list(inputs.shape[1:]), dtype = torch.float)], dim = 1)\n",
    "\n",
    "        \n",
    "        masks = self.get_masks(inputs, targets)\n",
    "        return inputs, targets, masks\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_df, test_df = folds[0]\n",
    "    orientation = 'Sagittal T2/STIR'\n",
    "\n",
    "    dataset = DetectDataset(args, train_df, orientation = orientation)\n",
    "\n",
    "    index = random.randint(0, len(dataset) - 1)\n",
    "    inputs, targets, masks = dataset[index]\n",
    "\n",
    "    print('inputs : ', inputs.shape)\n",
    "    print('targets : ', targets.shape)\n",
    "    print('masks : ', masks.shape)\n",
    "\n",
    "    print(volume2point(targets[None]))\n",
    "\n",
    "    fig, axes = plt.subplots(2, targets[0].shape[0], figsize = (5 * targets[0].shape[0], 5 * 2))\n",
    "    for i in range(targets[0].shape[0]):\n",
    "        axes[0, i].imshow(inputs[i], cmap = 'gray')\n",
    "        axes[1, i].imshow(targets[0][i], cmap = 'gray')\n",
    "    plt.show()\n",
    "    plt.imshow(targets[0].permute(1, 0, 2).reshape(256, -1))\n",
    "    plt.show()\n",
    "\n",
    "    patch_size = {'Sagittal T2/STIR' : 32, 'Sagittal T1' : 32, 'Axial T2' : 32}[orientation]\n",
    "    fig, axes = plt.subplots(2, targets.shape[0], figsize = (5 * targets.shape[0], 5 * 2))\n",
    "\n",
    "    points = volume2point(targets[None])[0]\n",
    "    for i in range(targets.shape[0]):\n",
    "        z, y, x = points[i]\n",
    "        if points[i].sum() != 0:\n",
    "            axes[0, i].imshow(inputs[z, y-patch_size:y+patch_size, x-patch_size:x+patch_size], cmap = 'gray')\n",
    "            axes[1, i].imshow(targets[i][z, y-patch_size:y+patch_size, x-patch_size:x+patch_size], cmap = 'gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nQo9CkvsVGWt"
   },
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MIZrthK4VGWu"
   },
   "outputs": [],
   "source": [
    "class Segmenter(nn.Module):\n",
    "    def __init__(self,\n",
    "                 n_class,\n",
    "                 n_channel,\n",
    "                 volume_size,\n",
    "                 backbone = 'tf_efficientnet_b5_ns',\n",
    "                 n_blocks = 4,\n",
    "                 ):\n",
    "        super(Segmenter, self).__init__()\n",
    "\n",
    "        \n",
    "        self.n_class = n_class\n",
    "        self.n_channel = n_channel\n",
    "        self.volume_size = volume_size\n",
    "\n",
    "        self.extracter = timm.create_model(backbone, \n",
    "                              pretrained=True,\n",
    "                              features_only = True,\n",
    "                              out_indices=range(n_blocks),\n",
    "                                      )\n",
    "\n",
    "        encoder_channels = [n_channel] + [self.extracter.feature_info[i][\"num_chs\"] for i in range(n_blocks)]\n",
    "        decoder_channels = [256, 128, 64, 32, 16, 8][:n_blocks]\n",
    "\n",
    "        self.decoder = UnetDecoder(\n",
    "            encoder_channels = encoder_channels,\n",
    "            decoder_channels = decoder_channels,\n",
    "            n_blocks = n_blocks,\n",
    "            use_batchnorm = True,\n",
    "            center = False,\n",
    "            attention_type = None,\n",
    "        )\n",
    "\n",
    "        self.head = SegmentationHead(\n",
    "            in_channels = decoder_channels[-1],\n",
    "            out_channels = self.n_class,\n",
    "            activation = None,\n",
    "            kernel_size= 3,\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.reshape(-1, self.n_channel, self.volume_size[1], self.volume_size[2])\n",
    "        _x = self.extracter(x)\n",
    "\n",
    "        x = self.decoder(*[x] + _x)\n",
    "        x = self.head(x)\n",
    "\n",
    "        x = x.reshape(-1, self.volume_size[0], self.n_class, self.volume_size[1], self.volume_size[2])\n",
    "        x = x.permute(0, 2, 1, 3, 4)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MW1KLgRPVGWv"
   },
   "outputs": [],
   "source": [
    "class Pointer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 n_class,\n",
    "                 n_channel,\n",
    "                 volume_size,\n",
    "                 hidden_size,\n",
    "                 drop_rate,\n",
    "                 is_lstm = True,\n",
    "                 ):\n",
    "        super(Pointer, self).__init__()\n",
    "\n",
    "        self.n_channel = n_channel\n",
    "        self.volume_size = volume_size\n",
    "        \n",
    "\n",
    "\n",
    "        self.is_lstm = is_lstm\n",
    "\n",
    "\n",
    "        if self.is_lstm:\n",
    "    \n",
    "            self.extractor = timm.create_model('regnety_002', \n",
    "                                  pretrained=True,\n",
    "                                  features_only = True,\n",
    "                                  in_chans = n_channel,\n",
    "                                              )\n",
    "    \n",
    "            self.dense_size = self.extractor.feature_info[-1][\"num_chs\"]\n",
    "            self.rnn = nn.LSTM(\n",
    "                input_size = self.dense_size,\n",
    "                hidden_size = hidden_size,\n",
    "                batch_first = True,\n",
    "                bidirectional = True\n",
    "                )\n",
    "            self.out = nn.Sequential(\n",
    "                    nn.Dropout(p = drop_rate),\n",
    "                    nn.Linear(2 * hidden_size, n_class)\n",
    "                )\n",
    "        else:\n",
    "            self.extracter = timm.create_model('regnety_002', \n",
    "                                  pretrained=True,\n",
    "                                  features_only = True,\n",
    "                                  in_chans = n_channel,\n",
    "                                              )\n",
    "    \n",
    "            self.dense_size = self.extracter.feature_info[-1][\"num_chs\"]\n",
    "\n",
    "            self.dense = nn.Linear(self.dense_size, hidden_size)\n",
    "    \n",
    "            self.transformer = RobertaPreLayerNormModel(\n",
    "                RobertaPreLayerNormConfig(\n",
    "                    hidden_size = hidden_size,\n",
    "                    num_hidden_layers = 1,\n",
    "                    num_attention_heads = 4,\n",
    "                    intermediate_size = 4 * hidden_size,\n",
    "                    hidden_act = 'gelu',\n",
    "                    )\n",
    "                )\n",
    "            del self.transformer.embeddings.word_embeddings\n",
    "\n",
    "            self.out = nn.Sequential(\n",
    "                nn.Dropout(p = drop_rate),\n",
    "                nn.Linear(hidden_size, n_class)\n",
    "            )\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        x = x.reshape(-1, self.n_channel, self.volume_size[1], self.volume_size[2])\n",
    "        if self.is_lstm:\n",
    "            x = self.extractor(x)\n",
    "            x = x[-1].mean(dim = [2, 3])\n",
    "            x = x.reshape(-1, self.volume_size[0], self.dense_size)\n",
    "            x, _ =  self.rnn(x)\n",
    "        else:\n",
    "            x = self.extracter(x)\n",
    "            x = x[-1].mean(dim = [2, 3])\n",
    "            x = x.reshape(-1, self.volume_size[0], self.dense_size)\n",
    "            x = self.dense(x)\n",
    "            x = self.transformer(inputs_embeds = x, attention_mask = mask).last_hidden_state\n",
    "        x = self.out(x)\n",
    "\n",
    "        x = x.permute(0, 2, 1)\n",
    "        return x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 222,
     "referenced_widgets": [
      "c8b28dffe8f94f36b906d029a69dfef9",
      "bd0637df9b9a4888a248ec7db213b07d",
      "6da0cec2ca884a1abb1b5e391d4ebefb",
      "3d0f09aa72d14b098638f7af5f6f4f86",
      "448bdd9ab64e4d26a9a583a4eefafbc1",
      "12f9accdbc1e469b993e2641b22627ad",
      "bf51b324ab3548f5bce4c97db7164b41",
      "4c5dcca653614874b579aea76d4e6c6b",
      "2e9482e54d6c4f2cb03cc3ea6c6d7a7a",
      "900279a331e54a5c86f9c476ddbe7e61",
      "8ffe4c0b2c9c4a6fb8abcc5d40594545"
     ]
    },
    "id": "_9CcAZtxVGWw",
    "outputId": "656d17f6-ac7b-412b-c4a6-cb280a44e311"
   },
   "outputs": [],
   "source": [
    "class DetectModel(nn.Module):\n",
    "    def __init__(self,\n",
    "                 args,\n",
    "                 orientation,\n",
    "                 n_channel = 3,\n",
    "                 hidden_size = 256,\n",
    "                 drop_rate = 0.3,                 \n",
    "                 ):\n",
    "\n",
    "        super(DetectModel, self).__init__()\n",
    "        self.args = args\n",
    "\n",
    "        self.orientation = orientation\n",
    "\n",
    "        n_class = {\n",
    "            'Sagittal T2/STIR' : 5,\n",
    "            'Sagittal T1' : 10,\n",
    "            'Axial T2' : 10,\n",
    "        }[orientation]\n",
    "\n",
    "        volume_size = {\n",
    "            'Sagittal T2/STIR' : [29, 256, 256],\n",
    "            'Sagittal T1' : [38, 256, 256],\n",
    "            'Axial T2' : [192, 256, 256]\n",
    "        }[orientation]\n",
    "\n",
    "        segmenter_backbone = {\n",
    "            'Sagittal T2/STIR' : 'tf_efficientnet_b5_ns',\n",
    "            'Sagittal T1' :'tf_efficientnet_b5_ns',\n",
    "            'Axial T2' : 'regnety_002'\n",
    "        }[orientation]\n",
    "\n",
    "        n_blocks = {\n",
    "            'Sagittal T2/STIR' : 4,\n",
    "            'Sagittal T1' :4,\n",
    "            'Axial T2' : 5\n",
    "        }[orientation]\n",
    "\n",
    "        is_lstm = {\n",
    "            'Sagittal T2/STIR' : True,\n",
    "            'Sagittal T1' :True,\n",
    "            'Axial T2' : False\n",
    "        }[orientation]\n",
    "\n",
    "        self.n_channel = n_channel\n",
    "        self.volume_size = volume_size\n",
    "\n",
    "        self.segmenter = Segmenter(\n",
    "            n_class = n_class,\n",
    "            n_channel = n_channel,\n",
    "            volume_size = volume_size,\n",
    "            backbone = segmenter_backbone,\n",
    "            n_blocks = n_blocks,\n",
    "            )\n",
    "\n",
    "        self.pointer = Pointer(\n",
    "            n_class = n_class,\n",
    "            n_channel = n_channel,\n",
    "            volume_size = volume_size,\n",
    "            hidden_size = hidden_size,\n",
    "            drop_rate = drop_rate,\n",
    "            is_lstm = is_lstm,\n",
    "        )\n",
    "\n",
    "    def get_inputs(self, x):\n",
    "        x = F.pad(x, (0, 0, 0, 0, (self.n_channel-1)//2, (self.n_channel-1)//2), \"constant\", 0)\n",
    "        x = [x[:, i:i+self.n_channel] for i in range(self.volume_size[0])]\n",
    "        x = torch.stack(x, dim = 1)\n",
    "        return x\n",
    "\n",
    "    def get_masks(self, x):\n",
    "        x = (x.sum(dim = [2, 3]) != 0).float()\n",
    "        return x\n",
    "\n",
    "    def get_outputs(self, x1, x2, mask):\n",
    "        x1 = torch.sigmoid(x1)\n",
    "        x2 = torch.sigmoid(x2)\n",
    "\n",
    "        x = x1 * x2[:, :, :, None, None] * mask[:, None, :, None, None]\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        mask = self.get_masks(x)\n",
    "\n",
    "        x = self.get_inputs(x)\n",
    "\n",
    "        x1 = self.segmenter(x)\n",
    "\n",
    "        x2 = self.pointer(x, mask)\n",
    "\n",
    "        return x1, x2, self.get_outputs(x1, x2, mask)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    loader = torch.utils.data.DataLoader(dataset, batch_size = args.batch_size, num_workers = args.n_worker)\n",
    "    sample = next(iter(loader))\n",
    "    sample = [x.to(args.device) for x in sample]\n",
    "\n",
    "    model = DetectModel(args, orientation = orientation)\n",
    "    model = model.to(args.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs1, outputs2, outputs = model(sample[0])\n",
    "        print(outputs1.shape)\n",
    "        print(outputs2.shape)\n",
    "        print(outputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mL1K3jc3Qsub"
   },
   "source": [
    "## inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SZGmq6onLZGl"
   },
   "outputs": [],
   "source": [
    "def inference(args, model, loader):\n",
    "    model.eval()\n",
    "\n",
    "    preds = np.zeros([len(loader.dataset.df), len(args.coordinate_columns[loader.dataset.orientation]), 3], dtype = int)\n",
    "    preds2 = np.zeros([len(loader.dataset.df), len(args.coordinate_columns[loader.dataset.orientation]), 1 + 9*2], dtype = int)\n",
    "    trues = np.zeros([len(loader.dataset.df), len(args.coordinate_columns[loader.dataset.orientation]), 3], dtype = int)\n",
    "    masks = np.zeros([len(loader.dataset.df), len(args.coordinate_columns[loader.dataset.orientation])], dtype = int)\n",
    "    for bi, sample in enumerate(tqdm(loader)):\n",
    "        sample = [x.to(args.device) for x in sample]\n",
    "\n",
    "        inputs = sample[0]\n",
    "        targets = sample[1]\n",
    "        _masks = sample[2]\n",
    "        with torch.no_grad():\n",
    "            _, _, outputs = model(inputs)\n",
    "\n",
    "        preds[(bi) * args.batch_size:(bi + 1) * args.batch_size, :, :] = volume2point(outputs)\n",
    "        preds2[(bi) * args.batch_size:(bi + 1) * args.batch_size, :, :] = volume2point2(outputs)\n",
    "        trues[(bi) * args.batch_size:(bi + 1) * args.batch_size, :, :] = volume2point(targets)\n",
    "        masks[(bi) * args.batch_size:(bi + 1) * args.batch_size, :] = (_masks.sum(2) != 0).long().cpu().numpy()\n",
    "\n",
    "    return preds, preds2, trues, masks\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    args = CustomConfig()\n",
    "\n",
    "    model_weights = {\n",
    "                'Sagittal T2/STIR' : [\n",
    "                    DATA_DIR + '/stage1/sagittal_t2/fold1/epoch030-trainloss0.164532-testloss0.183283-testscore0.92555.bin',\n",
    "                    DATA_DIR + '/stage1/sagittal_t2/fold2/epoch035-trainloss0.163079-testloss0.187091-testscore0.863966.bin',\n",
    "                    DATA_DIR + '/stage1/sagittal_t2/fold3/epoch040-trainloss0.162728-testloss0.184239-testscore0.881218.bin',\n",
    "                    DATA_DIR + '/stage1/sagittal_t2/fold4/epoch030-trainloss0.164352-testloss0.18379-testscore0.868186.bin',\n",
    "                    DATA_DIR + '/stage1/sagittal_t2/fold5/epoch025-trainloss0.16676-testloss0.183907-testscore0.856371.bin'\n",
    "                ],\n",
    "                'Sagittal T1' : [\n",
    "                    DATA_DIR + '/stage1/sagittal_t1/fold1/epoch040-trainloss0.177427-testloss0.193425-testscore0.986041.bin',\n",
    "                    DATA_DIR + '/stage1/sagittal_t1/fold2/epoch040-trainloss0.177861-testloss0.190003-testscore1.046954.bin',\n",
    "                    DATA_DIR + '/stage1/sagittal_t1/fold3/epoch040-trainloss0.176816-testloss0.196593-testscore1.07519.bin',\n",
    "                    DATA_DIR + '/stage1/sagittal_t1/fold4/epoch040-trainloss0.175746-testloss0.208547-testscore1.044726.bin',\n",
    "                    DATA_DIR + '/stage1/sagittal_t1/fold5/epoch040-trainloss0.176303-testloss0.194872-testscore1.036294.bin'\n",
    "                ],\n",
    "                'Axial T2' : [\n",
    "                    DATA_DIR + '/stage1/axial_t2/fold1/epoch035-trainloss0.095594-testloss0.102066-testscore1.408456.bin',\n",
    "                    DATA_DIR + '/stage1/axial_t2/fold1/epoch015-trainloss0.10231-testloss0.106541-testscore1.689291.bin',\n",
    "                    DATA_DIR + '/stage1/axial_t2/fold1/epoch015-trainloss0.10231-testloss0.106541-testscore1.689291.bin',\n",
    "                    DATA_DIR + '/stage1/axial_t2/fold1/epoch015-trainloss0.10231-testloss0.106541-testscore1.689291.bin',\n",
    "                    DATA_DIR + '/stage1/axial_t2/fold1/epoch015-trainloss0.10231-testloss0.106541-testscore1.689291.bin'\n",
    "                ]\n",
    "    }\n",
    "\n",
    "    for orientation in args.scan_orientations:\n",
    "        print('orientation : ', orientation)\n",
    "\n",
    "        for fold in range(args.n_fold):\n",
    "            print('fold :', fold)\n",
    "            model_weight = model_weights[orientation][fold]\n",
    "\n",
    "\n",
    "            save_name = {\n",
    "                    'Sagittal T2/STIR' : f'sgittal_t2_fold{fold+1}',\n",
    "                    'Sagittal T1' : f'sgittal_t1_fold{fold+1}',\n",
    "                    'Axial T2' : f'axial_t2_fold{fold+1}'\n",
    "            }[orientation]\n",
    "\n",
    "            model = DetectModel(args, orientation)\n",
    "            model = model.to(args.device)\n",
    "            model.load_state_dict(torch.load(model_weight))\n",
    "            model.eval()\n",
    "\n",
    "            train_df, test_df = folds[fold]\n",
    "            df = test_df\n",
    "    \n",
    "            dataset = DetectDataset(args, df, orientation)\n",
    "            loader = torch.utils.data.DataLoader(dataset,\n",
    "                                                batch_size = args.batch_size,\n",
    "                                                num_workers = args.n_worker,\n",
    "                                                shuffle = False,\n",
    "                                                drop_last = False)\n",
    "\n",
    "            preds, preds2, trues, masks = inference(args, model, loader)\n",
    "    \n",
    "            errors = np.abs(preds - trues)\n",
    "            z_diff = (errors[:, :, 0] * masks).sum() / masks.sum()\n",
    "            y_diff = (errors[:, :, 1] * masks).sum() / masks.sum()\n",
    "            x_diff = (errors[:, :, 2] * masks).sum() / masks.sum()\n",
    "            distance = (np.sqrt((errors ** 2).sum(2)) * masks).sum() / masks.sum()\n",
    "\n",
    "            score_dicts = {\n",
    "                'zyx mean difference' : (z_diff + y_diff + x_diff) / 3,\n",
    "                'z-axis difference' : z_diff,\n",
    "                'y-axis difference' : y_diff,\n",
    "                'x-axis difference' : x_diff,\n",
    "                'distance' : distance\n",
    "            }\n",
    "    \n",
    "            print(score_dicts)\n",
    "    \n",
    "            np.save(DATA_DIR + '/stage1/coordinates/' + save_name + f'_preds.npy', preds)\n",
    "            np.save(DATA_DIR + '/stage1/coordinates/' + save_name + f'_preds2.npy', preds2)\n",
    "            np.save(DATA_DIR + '/stage1/coordinates/' + save_name + f'_trues.npy', trues)\n",
    "            np.save(DATA_DIR + '/stage1/coordinates/' + save_name + f'_masks.npy', masks)\n",
    "\n",
    "            del preds, trues, masks"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "OgsKxoKnbsc_",
    "Mj3ahmv2bniB",
    "LfdZdnCESz3o",
    "t5O3mtxnTC6E",
    "JpOm4ClDTQuy",
    "iOaNHqoITdt4",
    "numIyizDD0FY"
   ],
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "12f9accdbc1e469b993e2641b22627ad": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2e9482e54d6c4f2cb03cc3ea6c6d7a7a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3d0f09aa72d14b098638f7af5f6f4f86": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_900279a331e54a5c86f9c476ddbe7e61",
      "placeholder": "​",
      "style": "IPY_MODEL_8ffe4c0b2c9c4a6fb8abcc5d40594545",
      "value": " 12.8M/12.8M [00:00&lt;00:00, 18.3MB/s]"
     }
    },
    "448bdd9ab64e4d26a9a583a4eefafbc1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4c5dcca653614874b579aea76d4e6c6b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6da0cec2ca884a1abb1b5e391d4ebefb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4c5dcca653614874b579aea76d4e6c6b",
      "max": 12764356,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2e9482e54d6c4f2cb03cc3ea6c6d7a7a",
      "value": 12764356
     }
    },
    "8ffe4c0b2c9c4a6fb8abcc5d40594545": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "900279a331e54a5c86f9c476ddbe7e61": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bd0637df9b9a4888a248ec7db213b07d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_12f9accdbc1e469b993e2641b22627ad",
      "placeholder": "​",
      "style": "IPY_MODEL_bf51b324ab3548f5bce4c97db7164b41",
      "value": "model.safetensors: 100%"
     }
    },
    "bf51b324ab3548f5bce4c97db7164b41": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c8b28dffe8f94f36b906d029a69dfef9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bd0637df9b9a4888a248ec7db213b07d",
       "IPY_MODEL_6da0cec2ca884a1abb1b5e391d4ebefb",
       "IPY_MODEL_3d0f09aa72d14b098638f7af5f6f4f86"
      ],
      "layout": "IPY_MODEL_448bdd9ab64e4d26a9a583a4eefafbc1"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
